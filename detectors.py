import torch
from PIL import Image
from transformers import Owlv2Processor, Owlv2ForObjectDetection
from abc import ABC, abstractmethod
from ultralytics import YOLO

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å GroundingDINO
HAS_GROUNDING_DINO = False
try:
    from groundingdino.models import build_model as gd_build_model  # type: ignore

    HAS_GROUNDING_DINO = True
except Exception:
    HAS_GROUNDING_DINO = False


class DetectorBase(ABC):
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–æ–≤ –æ–±—ä–µ–∫—Ç–æ–≤"""

    def __init__(self, device='gpu'):
        self.device = device

    @abstractmethod
    def detect(self, image: Image.Image, text_queries: list, box_threshold=0.3):
        """
        –î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç –æ–±—ä–µ–∫—Ç—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –ø–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–º –∑–∞–ø—Ä–æ—Å–∞–º.

        Args:
            image: PIL Image –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            text_queries: –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ–±—ä–µ–∫—Ç–æ–≤
            box_threshold: –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

        Returns:
            –°–ø–∏—Å–æ–∫ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏ –∏ –º–µ—Ç–∫–∞–º–∏
        """
        pass


class OwlViTDetector(DetectorBase):
    """–î–µ—Ç–µ–∫—Ç–æ—Ä –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ OWL-ViT"""

    def __init__(self, model_name='google/owlv2-base-patch16-ensemble', device='gpu'):
        super().__init__(device)
        print(f"üîç Loading OWL-ViT model: {model_name} ...")
        self.processor = Owlv2Processor.from_pretrained(model_name)
        self.model = Owlv2ForObjectDetection.from_pretrained(model_name).to(device)

    def detect(self, image: Image.Image, text_queries: list, box_threshold=0.3, visualize=True):
        """
        –î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç –æ–±—ä–µ–∫—Ç—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –ø–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–º –∑–∞–ø—Ä–æ—Å–∞–º.

        Args:
            image: PIL Image –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            text_queries: –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ–±—ä–µ–∫—Ç–æ–≤
            box_threshold: –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            visualize: –§–ª–∞–≥ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

        Returns:
            detections: [
                {"bbox": (x0, y0, x1, y1), "score": float, "label": "cat"}
            ],
            annotated_image: PIL.Image (–µ—Å–ª–∏ visualize=True)
        """
        # 1Ô∏è‚É£ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        inputs = self.processor(text=text_queries, images=image, return_tensors="pt").to(self.model.device)

        # 2Ô∏è‚É£ –ü—Ä–æ–≥–æ–Ω —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å
        with torch.no_grad():
            outputs = self.model(**inputs)

        # 3Ô∏è‚É£ –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞
        target_sizes = torch.tensor([image.size[::-1]]).to(self.model.device)  # (H, W)
        results = self.processor.post_process_object_detection(
            outputs=outputs,
            threshold=box_threshold,
            target_sizes=target_sizes
        )[0]

        detections = []
        for score, label, box in zip(results["scores"], results["labels"], results["boxes"]):
            detections.append({
                "bbox": tuple(map(float, box.tolist())),
                "score": float(score.item()),
                "label": text_queries[label] if label < len(text_queries) else str(label)
            })

        return detections, image


class YOLOv8Detector(DetectorBase):
    """YOLOv8 –¥–µ—Ç–µ–∫—Ç–æ—Ä —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏"""

    def __init__(self, model_name='yolov8x-seg.pt', device='gpu'):
        super().__init__(device)
        print(f"üß† Loading YOLOv8 model: {model_name} ...")
        self.model = YOLO(model_name)
        self.model.to(device)

    def detect(self, image: Image.Image, text_queries=None, box_threshold=0.3, visualize=True):
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é –∏ –¥–µ—Ç–µ–∫—Ü–∏—é –æ–±—ä–µ–∫—Ç–æ–≤ YOLOv8.

        Args:
            image: PIL.Image
            text_queries: –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç—Å—è (YOLO –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–µ–∫—Å—Ç)
            box_threshold: –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            visualize: —Ä–∏—Å–æ–≤–∞—Ç—å –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç

        Returns:
            detections: [
                {"bbox": (x0, y0, x1, y1), "score": float, "label": str, "mask": np.ndarray | None}
            ],
            annotated_image: PIL.Image (–µ—Å–ª–∏ visualize=True)
        """
        results = self.model.predict(image, conf=box_threshold, device=self.device, verbose=False)
        detections = []

        for r in results:
            boxes = r.boxes
            masks = getattr(r, 'masks', None)
            names = self.model.names

            for i, box in enumerate(boxes):
                xyxy = box.xyxy[0].tolist()
                score = float(box.conf.item())
                cls = int(box.cls.item())
                label = names.get(cls, str(cls))

                mask = None
                if masks is not None and len(masks.data) > i:
                    mask = masks.data[i].cpu().numpy()

                detections.append({
                    "bbox": tuple(map(float, xyxy)),
                    "score": score,
                    "label": label,
                    "mask": mask  # np.ndarray (H, W) –∏–ª–∏ None
                })

        return detections, image

class GroundingDINOPlaceholder(DetectorBase):
    """
    –ó–∞–≥–ª—É—à–∫–∞/—Å–∫–µ–ª–µ—Ç –¥–ª—è Grounding DINO.
    –ß—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–µ–∞–ª—å–Ω—É—é Grounding DINO, —É—Å—Ç–∞–Ω–æ–≤–∏ –µ—ë —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –∏ –∏–º–ø–æ—Ä—Ç—ã,
    –∑–∞—Ç–µ–º –∑–∞–º–µ–Ω–∏ –ª–æ–≥–∏–∫—É –≤ detect() –Ω–∞ –≤—ã–∑–æ–≤—ã –∏–∑ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ GroundingDINO.predictor.
    """

    def __init__(self, device='cpu'):
        super().__init__(device)
        if not HAS_GROUNDING_DINO:
            raise RuntimeError("Grounding DINO –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏ repo IDEA-Research/GroundingDINO –∏ –ø–æ–≤—Ç–æ—Ä–∏.")
        # TODO: –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏

    def detect(self, image: Image.Image, text_queries: list, box_threshold=0.3):
        # TODO: –∑–∞–º–µ–Ω–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–º –≤—ã–∑–æ–≤–æ–º Grounding DINO
        raise NotImplementedError(
            "–¢—Ä–µ–±—É–µ—Ç—Å—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è Grounding DINO. –°–µ–π—á–∞—Å –∏—Å–ø–æ–ª—å–∑—É–π OWL-ViT –∏–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏ Grounding DINO.")