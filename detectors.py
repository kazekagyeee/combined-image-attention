import torch
from PIL import Image, ImageDraw, ImageFont
from transformers import OwlViTProcessor, OwlViTForObjectDetection
from abc import ABC, abstractmethod

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å GroundingDINO
HAS_GROUNDING_DINO = False
try:
    from groundingdino.models import build_model as gd_build_model  # type: ignore

    HAS_GROUNDING_DINO = True
except Exception:
    HAS_GROUNDING_DINO = False


class DetectorBase(ABC):
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–æ–≤ –æ–±—ä–µ–∫—Ç–æ–≤"""

    def __init__(self, device='cpu'):
        self.device = device

    @abstractmethod
    def detect(self, image: Image.Image, text_queries: list, box_threshold=0.3):
        """
        –î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç –æ–±—ä–µ–∫—Ç—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –ø–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–º –∑–∞–ø—Ä–æ—Å–∞–º.

        Args:
            image: PIL Image –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            text_queries: –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ–±—ä–µ–∫—Ç–æ–≤
            box_threshold: –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

        Returns:
            –°–ø–∏—Å–æ–∫ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏ –∏ –º–µ—Ç–∫–∞–º–∏
        """
        pass


class OwlViTDetector(DetectorBase):
    """–î–µ—Ç–µ–∫—Ç–æ—Ä –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ OWL-ViT"""

    def __init__(self, model_name='google/owlvit-base-patch32', device='gpu'):
        super().__init__(device)
        print(f"üîç Loading OWL-ViT model: {model_name} ...")
        self.processor = OwlViTProcessor.from_pretrained(model_name)
        self.model = OwlViTForObjectDetection.from_pretrained(model_name).to(device)

    def detect(self, image: Image.Image, text_queries: list, box_threshold=0.3, visualize=True):
        """
        –î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç –æ–±—ä–µ–∫—Ç—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –ø–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–º –∑–∞–ø—Ä–æ—Å–∞–º.

        Args:
            image: PIL Image –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            text_queries: –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ–±—ä–µ–∫—Ç–æ–≤
            box_threshold: –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            visualize: –§–ª–∞–≥ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

        Returns:
            detections: [
                {"bbox": (x0, y0, x1, y1), "score": float, "label": "cat"}
            ],
            annotated_image: PIL.Image (–µ—Å–ª–∏ visualize=True)
        """
        # 1Ô∏è‚É£ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        inputs = self.processor(text=text_queries, images=image, return_tensors="pt").to(self.model.device)

        # 2Ô∏è‚É£ –ü—Ä–æ–≥–æ–Ω —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å
        with torch.no_grad():
            outputs = self.model(**inputs)

        # 3Ô∏è‚É£ –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞
        target_sizes = torch.tensor([image.size[::-1]]).to(self.model.device)  # (H, W)
        results = self.processor.post_process_object_detection(
            outputs=outputs,
            threshold=box_threshold,
            target_sizes=target_sizes
        )[0]

        detections = []
        for score, label, box in zip(results["scores"], results["labels"], results["boxes"]):
            detections.append({
                "bbox": tuple(map(float, box.tolist())),
                "score": float(score.item()),
                "label": text_queries[label] if label < len(text_queries) else str(label)
            })

        # 4Ô∏è‚É£ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        annotated_image = image.copy()
        if visualize:
            draw = ImageDraw.Draw(annotated_image)
            try:
                font = ImageFont.truetype("arial.ttf", size=16)
            except:
                font = ImageFont.load_default()

            for det in detections:
                x0, y0, x1, y1 = det["bbox"]
                label = det["label"]
                score = det["score"]
                color = (255, 0, 0)  # –∫—Ä–∞—Å–Ω—ã–π bbox
                draw.rectangle([x0, y0, x1, y1], outline=color, width=3)
                text = f"{label} {score:.2f}"
                bbox = draw.textbbox((x0, y0 - 16), text, font=font)
                draw.rectangle(bbox, fill=color)
                draw.text((x0, y0 - 16), text, fill="white", font=font)

        return detections, annotated_image


class GroundingDINOPlaceholder(DetectorBase):
    """
    –ó–∞–≥–ª—É—à–∫–∞/—Å–∫–µ–ª–µ—Ç –¥–ª—è Grounding DINO.
    –ß—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–µ–∞–ª—å–Ω—É—é Grounding DINO, —É—Å—Ç–∞–Ω–æ–≤–∏ –µ—ë —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –∏ –∏–º–ø–æ—Ä—Ç—ã,
    –∑–∞—Ç–µ–º –∑–∞–º–µ–Ω–∏ –ª–æ–≥–∏–∫—É –≤ detect() –Ω–∞ –≤—ã–∑–æ–≤—ã –∏–∑ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ GroundingDINO.predictor.
    """

    def __init__(self, device='cpu'):
        super().__init__(device)
        if not HAS_GROUNDING_DINO:
            raise RuntimeError("Grounding DINO –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏ repo IDEA-Research/GroundingDINO –∏ –ø–æ–≤—Ç–æ—Ä–∏.")
        # TODO: –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏

    def detect(self, image: Image.Image, text_queries: list, box_threshold=0.3):
        # TODO: –∑–∞–º–µ–Ω–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–º –≤—ã–∑–æ–≤–æ–º Grounding DINO
        raise NotImplementedError(
            "–¢—Ä–µ–±—É–µ—Ç—Å—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è Grounding DINO. –°–µ–π—á–∞—Å –∏—Å–ø–æ–ª—å–∑—É–π OWL-ViT –∏–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏ Grounding DINO.")